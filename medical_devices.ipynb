{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHY4tA2cUMC6",
        "outputId": "dbe1002c-92fc-4815-efd1-abcc5aff8767"
      },
      "outputs": [],
      "source": [
        "!pip install Pillow opencv-python numpy matplotlib seaborn\n",
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLvBWJEtNJN2"
      },
      "outputs": [],
      "source": [
        "# Cell 2: Import Libraries\n",
        "# This cell imports all the modules needed for data preprocessing.\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from collections import defaultdict\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAufdSHiUUDl",
        "outputId": "3c76b328-21ba-4b89-aa5a-1683ce23a1cc"
      },
      "outputs": [],
      "source": [
        "# Cell 4: After Manual Annotation: Structure Data for YOLO Training (REVISED)\n",
        "# This cell is revised to correctly process the 'train', 'val', 'test' structure from Roboflow's export.\n",
        "\n",
        "print(\"\\n--- Step 2: AFTER MANUAL ANNOTATION: Structure Data for YOLO Training (REVISED) ---\")\n",
        "print(\"This code processes the output from your Roboflow export and organizes it for model training.\")\n",
        "\n",
        "# IMPORTANT: Configure this path AFTER you have completed the manual annotation and exported your data from Roboflow.\n",
        "# This 'roboflow_export_root' should be the path to the folder that Roboflow unzipped to.\n",
        "# For example, if you unzipped 'your_project_name.zip' to 'my_roboflow_data', then set this to 'my_roboflow_data'.\n",
        "roboflow_export_root = 'annotation_data'\n",
        "\n",
        "# Define the final main dataset directory for YOLO training (detection model).\n",
        "yolo_dataset_dir = 'yolo_medical_device_dataset'\n",
        "os.makedirs(os.path.join(yolo_dataset_dir, 'images', 'train'), exist_ok=True)\n",
        "os.makedirs(os.path.join(yolo_dataset_dir, 'images', 'val'), exist_ok=True)\n",
        "os.makedirs(os.path.join(yolo_dataset_dir, 'images', 'test'), exist_ok=True)\n",
        "os.makedirs(os.path.join(yolo_dataset_dir, 'labels', 'train'), exist_ok=True)\n",
        "os.makedirs(os.path.join(yolo_dataset_dir, 'labels', 'val'), exist_ok=True)\n",
        "os.makedirs(os.path.join(yolo_dataset_dir, 'labels', 'test'), exist_ok=True)\n",
        "\n",
        "# Define your class names for YOLO. These MUST match the labels used in your annotation tool\n",
        "# and be in the same order as the class IDs (0, 1, 2, 3, 4) in your YOLO .txt files.\n",
        "# Make sure the order here matches the order Roboflow assigned (usually alphabetical or by creation order).\n",
        "yolo_class_names = ['bp_monitor', 'glucose_meter', 'hba1c', 'spo2', 'weighing_scale']\n",
        "\n",
        "# Collect all image and label file paths from Roboflow's train, val, test subdirectories\n",
        "all_images = []\n",
        "all_labels = []\n",
        "\n",
        "# Roboflow typically exports with 'train', 'valid' (or 'val'), and 'test' subfolders.\n",
        "# We will iterate through these.\n",
        "roboflow_splits = ['train', 'valid', 'test']\n",
        "\n",
        "for split_folder in roboflow_splits:\n",
        "    images_path = os.path.join(roboflow_export_root, split_folder, 'images')\n",
        "    labels_path = os.path.join(roboflow_export_root, split_folder, 'labels')\n",
        "\n",
        "    if not os.path.exists(images_path) or not os.path.exists(labels_path):\n",
        "        print(f\"Warning: '{split_folder}/images' or '{split_folder}/labels' not found in '{roboflow_export_root}'. Skipping this split.\")\n",
        "        continue\n",
        "\n",
        "    for img_name in os.listdir(images_path):\n",
        "        if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            img_base_name = os.path.splitext(img_name)[0]\n",
        "            label_file_name = img_base_name + '.txt'\n",
        "            label_path = os.path.join(labels_path, label_file_name)\n",
        "\n",
        "            if os.path.exists(label_path):\n",
        "                all_images.append(os.path.join(images_path, img_name))\n",
        "                all_labels.append(label_path)\n",
        "            else:\n",
        "                print(f\"Warning: No label found for image: {os.path.join(images_path, img_name)}. Skipping.\")\n",
        "\n",
        "# Create a list of (image_path, label_path) tuples\n",
        "valid_pairs = list(zip(all_images, all_labels))\n",
        "\n",
        "print(f\"Found {len(valid_pairs)} valid image-label pairs collected from Roboflow export.\")\n",
        "\n",
        "# Shuffle and split the data for reproducibility (even if Roboflow pre-split, we re-split for consistency)\n",
        "random.seed(42) # For reproducibility\n",
        "random.shuffle(valid_pairs)\n",
        "\n",
        "train_split_ratio = 0.7\n",
        "val_split_ratio = 0.2\n",
        "test_split_ratio = 0.1\n",
        "\n",
        "num_samples = len(valid_pairs)\n",
        "num_train = int(num_samples * train_split_ratio)\n",
        "num_val = int(num_samples * val_split_ratio)\n",
        "num_test = num_samples - num_train - num_val # Ensures all samples are covered\n",
        "\n",
        "train_data = valid_pairs[:num_train]\n",
        "val_data = valid_pairs[num_train : num_train + num_val]\n",
        "test_data = valid_pairs[num_train + num_val :]\n",
        "\n",
        "print(f\"Splitting data: Train={len(train_data)}, Validation={len(val_data)}, Test={len(test_data)}\")\n",
        "\n",
        "# Function to copy files to their respective directories\n",
        "def copy_files_to_split(data_list, split_name, base_dir):\n",
        "    print(f\"Copying files for {split_name} split...\")\n",
        "    for img_path, lbl_path in data_list:\n",
        "        # Copy image\n",
        "        dest_img_path = os.path.join(base_dir, 'images', split_name, os.path.basename(img_path))\n",
        "        shutil.copy(img_path, dest_img_path)\n",
        "        # Copy label\n",
        "        dest_lbl_path = os.path.join(base_dir, 'labels', split_name, os.path.basename(lbl_path))\n",
        "        shutil.copy(lbl_path, dest_lbl_path)\n",
        "\n",
        "copy_files_to_split(train_data, 'train', yolo_dataset_dir)\n",
        "copy_files_to_split(val_data, 'val', yolo_dataset_dir)\n",
        "copy_files_to_split(test_data, 'test', yolo_dataset_dir)\n",
        "\n",
        "print(\"\\nData organized into YOLO format successfully!\")\n",
        "print(f\"Check the '{yolo_dataset_dir}' directory for the structured dataset.\")\n",
        "\n",
        "# Create data.yaml for the Detection Model.\n",
        "detection_data_yaml_content = f\"\"\"\n",
        "path: {os.path.abspath(yolo_dataset_dir)}\n",
        "train: images/train\n",
        "val: images/val\n",
        "test: images/test\n",
        "\n",
        "# Classes\n",
        "nc: {len(yolo_class_names)}\n",
        "names: {yolo_class_names}\n",
        "\"\"\"\n",
        "\n",
        "with open(os.path.join(yolo_dataset_dir, 'detection_data.yaml'), 'w') as f:\n",
        "    f.write(detection_data_yaml_content)\n",
        "\n",
        "print(f\"detection_data.yaml created in {yolo_dataset_dir}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7FJJLNPUd8N",
        "outputId": "d9dd7155-1dab-4d87-b61b-fd3b3296c9e7"
      },
      "outputs": [],
      "source": [
        "# Cell 5: Prepare Cropped Images for Classification Model (CORRECTED AGAIN for YAML path)\n",
        "# This cell generates a separate dataset of cropped device images, organized by class,\n",
        "# which is required for training the classification model.\n",
        "\n",
        "print(\"\\n--- Step 3: Preparing Cropped Images for Classification Model ---\")\n",
        "print(\"This step generates a separate dataset of cropped device images, organized by class.\")\n",
        "\n",
        "classification_dataset_path = 'classification_dataset'\n",
        "os.makedirs(os.path.join(classification_dataset_path, 'train'), exist_ok=True)\n",
        "os.makedirs(os.path.join(classification_dataset_path, 'val'), exist_ok=True)\n",
        "os.makedirs(os.path.join(classification_dataset_path, 'test'), exist_ok=True)\n",
        "\n",
        "# Function to crop images based on YOLO labels\n",
        "def crop_and_save_images(data_list, split_name, base_yolo_dir, base_cls_dir, class_names_map):\n",
        "    print(f\"Cropping and saving for {split_name} split...\")\n",
        "    for img_path, lbl_path in data_list:\n",
        "        try:\n",
        "            img = Image.open(img_path).convert(\"RGB\")\n",
        "            img_width, img_height = img.size\n",
        "\n",
        "            with open(lbl_path, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "\n",
        "            for i, line in enumerate(lines): # Enumerate to create unique names for multiple crops from one image\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) == 5:\n",
        "                    class_id = int(parts[0])\n",
        "                    # Ensure class_id is within the bounds of the class_names_map\n",
        "                    if class_id >= len(class_names_map) or class_id < 0:\n",
        "                        print(f\"Warning: Class ID {class_id} out of bounds for {img_path}. Skipping bounding box.\")\n",
        "                        continue\n",
        "\n",
        "                    class_label = class_names_map[class_id]\n",
        "                    # YOLO format: center_x, center_y, width, height (normalized)\n",
        "                    center_x, center_y, bbox_width, bbox_height = map(float, parts[1:])\n",
        "\n",
        "                    # Convert normalized coordinates to pixel coordinates\n",
        "                    x_center_px = center_x * img_width\n",
        "                    y_center_px = center_y * img_height\n",
        "                    bbox_width_px = bbox_width * img_width\n",
        "                    bbox_height_px = bbox_height * img_height\n",
        "\n",
        "                    # Calculate xmin, ymin, xmax, ymax\n",
        "                    xmin = int(x_center_px - (bbox_width_px / 2))\n",
        "                    ymin = int(y_center_px - (bbox_height_px / 2))\n",
        "                    xmax = int(x_center_px + (bbox_width_px / 2))\n",
        "                    ymax = int(y_center_px + (bbox_height_px / 2))\n",
        "\n",
        "                    # Ensure coordinates are within image bounds\n",
        "                    xmin = max(0, xmin)\n",
        "                    ymin = max(0, ymin) # Corrected line from previous fix\n",
        "                    xmax = min(img_width, xmax)\n",
        "                    ymax = min(img_height, ymax)\n",
        "\n",
        "                    if xmax <= xmin or ymax <= ymin:\n",
        "                        print(f\"Warning: Invalid bounding box for {img_path}. Skipping cropping.\")\n",
        "                        continue\n",
        "\n",
        "                    cropped_img = img.crop((xmin, ymin, xmax, ymax))\n",
        "\n",
        "                    # Create destination folder for this class if it doesn't exist\n",
        "                    dest_class_folder = os.path.join(base_cls_dir, split_name, class_label)\n",
        "                    os.makedirs(dest_class_folder, exist_ok=True)\n",
        "\n",
        "                    # Save the cropped image with a unique name\n",
        "                    original_img_name_base = os.path.splitext(os.path.basename(img_path))[0]\n",
        "                    # Add index (i) for multiple crops from the same original image\n",
        "                    cropped_img_name = f\"{original_img_name_base}_crop{i}.jpg\"\n",
        "                    cropped_img.save(os.path.join(dest_class_folder, cropped_img_name))\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {img_path}: {e}\")\n",
        "\n",
        "# Pass the yolo_class_names list directly for mapping class IDs to names.\n",
        "crop_and_save_images(train_data, 'train', yolo_dataset_dir, classification_dataset_path, yolo_class_names)\n",
        "crop_and_save_images(val_data, 'val', yolo_dataset_dir, classification_dataset_path, yolo_class_names)\n",
        "crop_and_save_images(test_data, 'test', yolo_dataset_dir, classification_dataset_path, yolo_class_names)\n",
        "\n",
        "print(\"\\nCropped images for classification model prepared successfully!\")\n",
        "print(f\"Check the '{classification_dataset_path}' directory for the structured classification dataset.\")\n",
        "\n",
        "# --- CORRECTED PART FOR classification_data.yaml CONTENT ---\n",
        "# Changed 'path: {os.path.abspath(classification_dataset_path)}' to 'path: .'\n",
        "classification_data_yaml_content = f\"\"\"\n",
        "# Path is relative to where this YAML file (classification_data.yaml) is located\n",
        "path: {os.path.abspath(classification_dataset_path)}\n",
        "train: train\n",
        "val: val\n",
        "test: test # Added test split as well for completeness if you need to evaluate it\n",
        "\n",
        "# Classes\n",
        "nc: {len(yolo_class_names)}\n",
        "names: {yolo_class_names}\n",
        "\"\"\"\n",
        "\n",
        "with open(os.path.join(classification_dataset_path, 'classification_data.yaml'), 'w') as f:\n",
        "    f.write(classification_data_yaml_content)\n",
        "\n",
        "print(f\"classification_data.yaml created in {classification_dataset_path}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4soF0wVNKHN",
        "outputId": "3fc1ae99-dcd8-41ca-cf35-6b6006c3f367"
      },
      "outputs": [],
      "source": [
        "# Cell 2: Import YOLO and Set Up Paths (UPDATED for Absolute Paths)\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "\n",
        "# Define the relative paths to your data.yaml files created during preprocessing\n",
        "relative_detection_data_yaml_path = 'yolo_medical_device_dataset/detection_data.yaml'\n",
        "relative_classification_data_yaml_path = 'classification_dataset/classification_data.yaml'\n",
        "\n",
        "# Get the absolute paths for robust use in Colab\n",
        "detection_data_yaml_path = os.path.abspath(relative_detection_data_yaml_path)\n",
        "classification_data_yaml_path = os.path.abspath(relative_classification_data_yaml_path)\n",
        "\n",
        "\n",
        "print(f\"Absolute Detection data YAML path: {detection_data_yaml_path}\")\n",
        "print(f\"Absolute Classification data YAML path: {classification_data_yaml_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puw-nMWkNKDs",
        "outputId": "fcafb953-449d-4aa3-88b6-ccb1863a2e5a"
      },
      "outputs": [],
      "source": [
        "# Cell 3: Train the Device Detection Model\n",
        "\n",
        "print(\"--- Starting Device Detection Model Training ---\")\n",
        "\n",
        "# Load a pre-trained YOLOv8 detection model (e.g., 'yolov8n.pt' for the nano version)\n",
        "# This model has learned general features and will be fine-tuned on your specific medical device dataset.\n",
        "model_detection = YOLO('yolov8n.pt')\n",
        "\n",
        "# Train the detection model\n",
        "results_detection = model_detection.train(\n",
        "    data=detection_data_yaml_path,\n",
        "    epochs=100,\n",
        "    imgsz=640,\n",
        "    batch=16,\n",
        "    name='device_detection_model_v1',\n",
        "    # Fine-tuning techniques as per requirements:\n",
        "    lr0=0.01,\n",
        "    lrf=0.01,\n",
        "    optimizer='AdamW',\n",
        "    fliplr=0.5,\n",
        "    mosaic=1.0,\n",
        "    patience=50,                  # Stop training if no improvement for this many epochs\n",
        "    cache=True,                   # Cache images for faster training (if enough RAM)\n",
        ")\n",
        "\n",
        "print(\"\\n--- Device Detection Model Training Complete ---\")\n",
        "print(f\"Model weights saved at: runs/detect/{results_detection.save_dir}/weights/best.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZQxa15iNKAW",
        "outputId": "a798fd56-b824-4609-a198-291bb092f06e"
      },
      "outputs": [],
      "source": [
        "# Cell 4: Train the Device Classification Model\n",
        "\n",
        "print(\"\\n--- Starting Device Classification Model Training ---\")\n",
        "\n",
        "# Load a YOLOv8 classification model architecture from scratch (no pre-trained weights)\n",
        "# 'yolov8n-cls.yaml' defines the smallest YOLOv8 classification model architecture.\n",
        "model_classification = YOLO('yolov8n-cls.yaml')\n",
        "\n",
        "# Train the classification model\n",
        "# Adjust epochs, batch size, and other parameters as needed.\n",
        "results_classification = model_classification.train(\n",
        "    data='classification_dataset', # Path to your classification dataset directory (parent folder of splits)\n",
        "    epochs=50,                          # Number of training epochs (adjust as needed)\n",
        "    imgsz=224,                          # Input image size (common for classification, e.g., 224x224)\n",
        "    batch=32,                           # Batch size (adjust based on your GPU memory)\n",
        "    name='device_classification_model_v1', # A name for this training run\n",
        "    # Fine-tuning techniques:\n",
        "    lr0=0.01,                           # Initial learning rate\n",
        "    optimizer='SGD',                    # SGD is a common optimizer for classification\n",
        "    patience=20,                      # Stop training if no improvement for this many epochs\n",
        ")\n",
        "\n",
        "print(\"\\n--- Device Classification Model Training Complete ---\")\n",
        "print(f\"Model weights saved at: runs/classify/{results_classification.save_dir}/weights/best.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QPNBq3pCNJ0u",
        "outputId": "aaaa62be-09e1-444d-ceec-3d892270b80f"
      },
      "outputs": [],
      "source": [
        "# To download the entire 'runs' folder (contains all detection and classification training results)\n",
        "!zip -r /content/runs.zip /content/runs/\n",
        "\n",
        "from google.colab import files\n",
        "files.download('/content/runs.zip')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
